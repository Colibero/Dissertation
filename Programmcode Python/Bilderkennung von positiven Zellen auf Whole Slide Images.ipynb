{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Christof/full_slides_ext/slides_tif/3604pylho1/3604pylho1_Wholeslide_Default_Extended.tif\n",
      "steps in x 1850 10\n",
      "steps in y 842 7\n",
      "number of tiles to classify 600943\n",
      "(32580, 20)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edd87067f9c4f6e95c8ae819c73263e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_model = 'D:/Christof/trained_networks/210618_adjusted_on_new_img_211008.pth' \n",
    "##read roi file with the regions marked as muscular layer to array and create list of all \n",
    "arr_results = []\n",
    "path_roi = 'D:/Christof/full_slides_ext/Annotation_Slides/'\n",
    "\n",
    "list_roi = os.listdir(path_roi)\n",
    "\n",
    "for fname in list_roi:\n",
    "    ##selction of the stain\n",
    "    if 'ho1' in fname: \n",
    "        path_temp = path_roi + fname\n",
    "        ##load the coordinations of the muscular layer in the whole slide scan from geojson\n",
    "        with open(path_temp) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 3:\n",
    "            arr_coord = np.array([])    \n",
    "\n",
    "            coord_list = lines[8:-9]\n",
    "\n",
    "            arr_coord = np.zeros((len(coord_list), 2))\n",
    "\n",
    "            for coord in coord_list:\n",
    "                index = coord_list.index(coord)\n",
    "                coord = coord[11:-2]\n",
    "                if coord[-1] == ']':\n",
    "                    coord = coord[:-1]\n",
    "                for char in coord:\n",
    "                    if char == ',':\n",
    "                        ind = coord.index(char)\n",
    "                        y = int(coord[:ind])\n",
    "                        x = int(coord[ind+1:])\n",
    "\n",
    "                arr_coord[index] = y,x\n",
    "            arr_coord = arr_coord.astype(int)\n",
    "\n",
    "\n",
    "            fname_img = fname[:-4]\n",
    "\n",
    "            ##load the whole slide images as tif\n",
    "            from skimage import io\n",
    "            import matplotlib.pyplot as plt\n",
    "            import numpy as np\n",
    "            import cv2\n",
    "\n",
    "\n",
    "            path = 'D:/Christof/full_slides_ext/slides_tif/'\n",
    "            path = path + fname[:-9] + '/' + fname[:-9]+'_Wholeslide_Default_Extended.tif'\n",
    "\n",
    "            print(path)\n",
    "            img = io.imread(path)\n",
    "            pts = arr_coord\n",
    "\n",
    "            ##calculate area of the annotation\n",
    "            \n",
    "            def PolygonArea(corners):\n",
    "                n = len(corners) # of corners\n",
    "                area = 0.0\n",
    "                for i in range(n):\n",
    "                    j = (i + 1) % n\n",
    "                    area += corners[i][0] * corners[j][1]\n",
    "                    area -= corners[j][0] * corners[i][1]\n",
    "                area = abs(area) / 2.0\n",
    "                return area\n",
    "                print(area)\n",
    "\n",
    "\n",
    "            area = PolygonArea(pts)\n",
    "\n",
    "            area_mm2 = area * 0.000274909**2\n",
    "            \n",
    "            \n",
    "            ##create bounding rectangle for creating the mask\n",
    "            \n",
    "            rect = cv2.boundingRect(pts)\n",
    "            x,y,w,h = rect\n",
    "            im = img[y:y+h, x:x+w].copy()\n",
    "\n",
    "\n",
    "            ##create mask for classifying the relevant areas\n",
    "            pts = pts - pts.min(axis=0)\n",
    "\n",
    "            mask = np.zeros(im.shape[:2], np.uint8)\n",
    "            mask = cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "            im = Image.fromarray(im, 'RGB')\n",
    "            shape_im = np.shape(im)\n",
    "\n",
    "            x_size = shape_im[1]\n",
    "            y_size = shape_im[0]\n",
    "\n",
    "            ##definition of the step size and the number of steps needed to analyse the whole muscular layer\n",
    "            stepsize = 20\n",
    "            stepsis = stepsize\n",
    "\n",
    "            steps_x = x_size//stepsis -70//stepsize +1\n",
    "            rest_x = x_size%stepsize\n",
    "\n",
    "            steps_y = y_size//stepsis -70//stepsize +1\n",
    "            rest_y = y_size%stepsize\n",
    "\n",
    "            print('steps in x',steps_x, rest_x)\n",
    "            print('steps in y', steps_y, rest_y)\n",
    "\n",
    "            ##definition of the arrays for the results of the classification and the predicition\n",
    "            arr_result = np.zeros((steps_y, steps_x))\n",
    "            arr_sigmoid = np.zeros((steps_y, steps_x))\n",
    "            arr_pred = np.zeros((steps_y, steps_x))\n",
    "            \n",
    "            #create ductuibary with the coordinations inside the muscular layer mask\n",
    "            dict_img_coord = {}\n",
    "\n",
    "            \n",
    "            n=0\n",
    "            for y in range(0, steps_y):\n",
    "                \n",
    "                for x in range(0, steps_x):\n",
    "                    x_coord = int(x*stepsize)\n",
    "                    y_coord = int(y*stepsize)\n",
    "\n",
    "                    if mask[y_coord, x_coord] > 0:\n",
    "                        dict_img_coord[n] = (int(x * stepsize), int(y *stepsize))\n",
    "                        #x,y = dict_img_coord.get(n) \n",
    "                        n +=1\n",
    "            len_dict_coord = len(dict_img_coord)\n",
    "           \n",
    "\n",
    "            print('number of tiles to classify' ,len_dict_coord)\n",
    "\n",
    "            ##loading of AI model\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "            model = torchvision.models.resnet50()\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = nn.Linear(num_ftrs, 2)\n",
    "            model.load_state_dict(torch.load(path_model))\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "\n",
    "            ##definition of the image loader\n",
    "\n",
    "            loader = transforms.Compose([transforms.Resize((70,70)), transforms.ToTensor()])\n",
    "\n",
    "            def image_loader(image):\n",
    "                \"\"\"load image, returns cuda tensor\"\"\"\n",
    "                image = loader(image).float()\n",
    "                image = image.unsqueeze_(0).cuda()  #this is for VGG, may not be needed for ResNet\n",
    "                return image.cuda()  #assumes that you're using GPU \n",
    "\n",
    "            def add_margin(pil_img, top, right, bottom, left, color):\n",
    "                width, height  = pil_img.size\n",
    "                new_width = width + right + left\n",
    "                new_height = height + top + bottom\n",
    "                result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "                result.paste(pil_img, (left, top))\n",
    "                return result\n",
    "\n",
    "            ##classify images at all selected coordinations in the muscular layer and save the predictions in an array\n",
    "            for i in tqdm(range(0, len_dict_coord)):\n",
    "                coord = dict_img_coord.get(i)\n",
    "                x = coord[0]\n",
    "                y = coord[1]\n",
    "                left = x \n",
    "                top = y + 70\n",
    "                right = x + 70\n",
    "                bottom = y\n",
    "                im1 = im.crop((left, bottom, right, top, ))\n",
    "                fname = str(i) + '.tif'\n",
    "                image = image_loader(im1)\n",
    "                pred = model(image)\n",
    "                pred = val_pos = float(pred[0][1].cpu())\n",
    "                x_arr = int(x/stepsize)\n",
    "                y_arr = int(y/stepsize)\n",
    "                arr_result[y_arr, x_arr] = pred\n",
    "                arr_sigmoid[y_arr, x_arr] = 1/(1 + np.exp(-pred))\n",
    "\n",
    "\n",
    "\n",
    "            ##array with binary predictions\n",
    "            arr_pred = np.zeros((steps_y, steps_x ))\n",
    "            ##smoothened array with singel positives sorted out\n",
    "            arr_smooth = np.zeros((steps_y , steps_x ))\n",
    "\n",
    "\n",
    "            y_sig, x_sig = np.shape(arr_sigmoid)\n",
    "\n",
    "            ##stetting the threshold for the prediction\n",
    "            thresh = 0.55\n",
    "            for y in range(0, y_sig):\n",
    "                for x in range(0, x_sig):\n",
    "                    if arr_sigmoid[y,x] > thresh:\n",
    "                        arr_pred[y, x] = 1\n",
    "\n",
    "            ##smoothing the array\n",
    "            y_sig, x_sig = np.shape(arr_sigmoid)\n",
    "\n",
    "            smooth_area = 1\n",
    "            thresh_smooth = 0\n",
    "            for y in range(0, y_sig):\n",
    "                for x in range(0, x_sig):\n",
    "                    smooth = np.sum(arr_pred[y-smooth_area:y+smooth_area+1,x-smooth_area:x+smooth_area+1])\n",
    "                    if smooth > thresh_smooth:\n",
    "                        arr_smooth[y,x] = smooth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #check if in the sourrounding pixels are higher values for segmentation \n",
    "\n",
    "            list_test = []\n",
    "\n",
    "            arr_max = np.zeros((steps_y , steps_x ))\n",
    "            x_sm, y_sm = np.shape(arr_smooth)\n",
    "            \n",
    "            for y in range(0, y_sm -1):\n",
    "                for x in range(0, x_sm-1):\n",
    "                    list_neighbours = [arr_smooth[x-1,y-1], arr_smooth[x-1,y], arr_smooth[x-1,y+1], arr_smooth[x,y-1], arr_smooth[x,y+1], arr_smooth[x+1,y-1], arr_smooth[x+1,y], arr_smooth[x+1,y+1] ]\n",
    "                    val = arr_smooth[x,y]\n",
    "                    if val> 1.0:\n",
    "                        for neighbor in list_neighbours:\n",
    "                            if val < neighbor:\n",
    "                                val = 0\n",
    "                                arr_max[x,y] = 0.0\n",
    "                        if val > 0:\n",
    "                            arr_max[x,y] = 1.0\n",
    "                            list_test.append((x,y))\n",
    "                    else:\n",
    "                        arr_max[x,y] = 0.0\n",
    "\n",
    "            list_max = []\n",
    "\n",
    "            #combine the boxes, if they lay directly next to each other\n",
    "\n",
    "            for coord in list_test:\n",
    "                x = coord[0]\n",
    "                y = coord[1]\n",
    "                list_surround2 = []\n",
    "                list_surround = [(x+1, y), (x+1, y+1), (x, y+1)]\n",
    "                for coord2 in list_surround: \n",
    "                    x = coord2[0]\n",
    "                    y = coord2[1]\n",
    "                    list_auxil = [(x+1, y), (x-1,y),(x+1,y-1), (x, y-1),(x-1,y-1), (x+1, y+1), (x, y+1),(x-1,y+1)]\n",
    "                    for coord2 in list_auxil:\n",
    "                        if coord2 not in list_surround2:\n",
    "                            list_surround2.append(coord2)\n",
    "\n",
    "                list_temp = []\n",
    "                for i in list_surround2:\n",
    "                    if i in list_test:\n",
    "                        ind = list_test.index(i)\n",
    "                        del list_test[ind]\n",
    "                        list_temp.append(i)\n",
    "                list_x = []\n",
    "                list_y = []\n",
    "                for i in list_temp:\n",
    "                    list_x.append(i[0])\n",
    "                    list_y.append(i[1])\n",
    "                print(list_x)\n",
    "                new_coord = (np.mean(list_x), np.mean(list_y))\n",
    "                list_test.append(new_coord)\n",
    "\n",
    "                print(list_test)\n",
    "\n",
    "    \n",
    "\n",
    "            #check again if there are positives next to each other\n",
    "            for coord in list_test:\n",
    "                x = coord[0]\n",
    "                y = coord[1]\n",
    "                list_surround2 = []\n",
    "                list_surround = [(x,y),(x+1, y), (x-1,y),(x+1,y-1), (x, y-1),(x-1,y-1), (x+1, y+1), (x, y+1),(x-1,y+1)]\n",
    "\n",
    "                #print(list_surround)\n",
    "                list_temp = []\n",
    "                \n",
    "                for i in list_surround:\n",
    "                    if i in list_test:\n",
    "                        ind = list_test.index(i)\n",
    "                        del list_test[ind]\n",
    "                        list_temp.append(i)\n",
    "                        #print(list_temp)\n",
    "                list_x = []\n",
    "                list_y = []\n",
    "                for i in list_temp:\n",
    "                    list_x.append(i[0])\n",
    "                    list_y.append(i[1])\n",
    "                #print(np.mean(list_x))\n",
    "                new_coord = (np.mean(list_x), np.mean(list_y))\n",
    "                list_test.append(new_coord)\n",
    "           \n",
    "            ##check if there are cell neighbouring directly another using net with lower threshold\n",
    "            for i in tqdm(range(0, len(list_test))):\n",
    "                coord = list_test[i]\n",
    "                y = int(coord[0]*stepsize)\n",
    "                x = int(coord[1]*stepsize)\n",
    "                count_pos = 0\n",
    "                for n in range(0,3):\n",
    "                    for k in range(0,3):\n",
    "                        if k != 1:\n",
    "                            y_temp = y-45+45*k\n",
    "                            x_temp = x-45 + 45*n\n",
    "                            left = x_temp \n",
    "                            top = y_temp + 70\n",
    "                            right = x_temp + 70\n",
    "                            bottom = y_temp\n",
    "                            im1 = im.crop((left, bottom, right, top, ))\n",
    "                            fname = str(i) + '.tif'\n",
    "                            image = image_loader(im1)\n",
    "                            pred = model(image)\n",
    "                            pred = val_pos = float(pred[0][1].cpu())\n",
    "                            pred_sig = 1/(1 + np.exp(-pred))\n",
    "                            thresh_again = thresh *0.8\n",
    "                            if pred_sig > thresh_again:\n",
    "                                count_pos += 1\n",
    "                                list_test.append((x_temp, y_temp))\n",
    "\n",
    "\n",
    "            ##second round of classification on positive rois with higher threshold for higher accuracy\n",
    "\n",
    "            list_result = []\n",
    "\n",
    "            for i in range(0, len(list_test)):\n",
    "                coord = list_test[i]\n",
    "                #print(coord)\n",
    "                y = int(coord[0]*stepsize)\n",
    "                x = int(coord[1]*stepsize)\n",
    "                count_pos = 0\n",
    "                for n in range(0,3):\n",
    "                    for k in range(0,3):\n",
    "                        y_temp = y-7 +7*k\n",
    "                        x_temp = x-7 + 7*n\n",
    "                        left = x_temp \n",
    "                        top = y_temp + 70\n",
    "                        right = x_temp + 70\n",
    "                        bottom = y_temp\n",
    "                        im1 = im.crop((left, bottom, right, top, ))\n",
    "                        fname = str(i) + '.tif'\n",
    "                        image = image_loader(im1)\n",
    "                        pred = model(image)\n",
    "                        pred = val_pos = float(pred[0][1].cpu())\n",
    "                        pred_sig = 1/(1 + np.exp(-pred))\n",
    "                        thresh_again = thresh *1.3\n",
    "                        if pred_sig > thresh_again:\n",
    "                            count_pos += 1\n",
    "                if count_pos > 4:\n",
    "                    list_result.append(coord)\n",
    "\n",
    "\n",
    "            arr_results.append([fname_img, area_mm2, str(len(list_result)) ,list_result])\n",
    "            np.savetxt(\"210929_fullslideHO1_scan_adjusted_net.csv\", arr_results, delimiter =\", \", fmt ='% s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3d722c33c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marr_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlist_result\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"210813_fullslideHO1_scan.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\", \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'% s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arr_results' is not defined"
     ]
    }
   ],
   "source": [
    "arr_results.append([fname_img, str(len(list_result)) ,list_result])\n",
    "np.savetxt(\"210927_fullslideHO1_scan.txt\", arr_results, delimiter =\", \", fmt ='% s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('211029_fullslide_HO1_scan_0.25,x1.6.npy', arr_result, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr_reuslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3604pylho1.mrxs', 18.15446612188232, '463', 25.5033663282407], ['3605ppvho1.mrxs', 24.367121400325683, '561', 23.022826159207376], ['3606pglho1.mrxs', 154.3365829703167, '164', 1.0626126148687758], ['3606ppvho1.mrxs', 25.765203147742035, '693', 26.896741160014177], ['3607pglho1.mrxs', 15.241062665243595, '563', 36.939681462231015], ['3607pylho1.mrxs', 15.293558316039869, '243', 15.889042626864791], ['3701pylho1.mrxs', 39.03497120852008, '670', 17.16409617470809], ['3702pglho1.mrxs', 12.029374559651902, '238', 19.784902267345068], ['3702ppvho1.mrxs', 11.668613150737448, '633', 54.2480920245432], ['3703ppvho1.mrxs', 10.738253483878465, '294', 27.378753951132513], ['3704pylho1.mrxs', 292.3610021775231, '205', 0.7011879097182836], ['3708pglho1.mrxs', 19.813545874359665, '392', 19.78444456563829], ['3802pglho1.mrxs', 10.848650851174247, '338', 31.15594783506331], ['3802ppvho1.mrxs', 1.6277639459518443, '24', 14.744152590236824], ['3803pglho1.mrxs', 14.841531264943509, '182', 12.262885597923022], ['3806pylho1.mrxs', 11.480653354907792, '134', 11.67180959633427], ['3807ppvho1.mrxs', 24.221488191205843, '824', 34.01937954824641], ['3807pylho1.mrxs', 9.04160681777636, '301', 33.29054293847586], ['3902pglho1.mrxs', 12.365802759161312, '131', 10.593731968023468], ['3902pylho1.mrxs', 6.16175777350238, '91', 14.768513035570864], ['3903ppvho1.mrxs', 25.173125723056486, '219', 8.69975395226403], ['3907pglho1.mrxs', 13.277735059517598, '139', 10.468652927395443], ['4002ppvho1.mrxs', 18.718928683536863, '124', 6.6243107229238465], ['4004ppvho1.mrxs', 30.9192805901431, '1148', 37.12893631703631], ['4004pylho1.mrxs', 22.502626832929227, '213', 9.465561580051018], ['4006pglho1.mrxs', 20.320067269386477, '485', 23.868031221072016], ['4007pglho1.mrxs', 19.060182722007305, '416', 21.825603986454823], ['4007pylho1.mrxs', 3.2587087663227776, '58', 17.7984607275749], ['4102pglho1.mrxs', 10.571536259534952, '152', 14.378231911459817], ['4102ppvho1.mrxs', 8.527759299656227, '37', 4.338771616301548], ['4102pylho1.mrxs', 27.518042327087162, '381', 13.84546166007477], ['4105pglho1.mrxs', 18.92171590830646, '408', 21.562526463093747], ['4107ppvho1.mrxs', 24.32479175283006, '340', 13.977509178899458], ['4107pylho1.mrxs', 23.327643472339822, '247', 10.588296254307648], ['4202pglho1.mrxs', 17.444504345508967, '162', 9.286592315344654], ['4202ppvho1.mrxs', 30.419899479387198, '803', 26.397194393890754], ['4202pylho1.mrxs', 23.28066048572544, '398', 17.095734901680906], ['4207pglho1.mrxs', 18.45700817274761, '150', 8.126994288352758], ['4207ppvho1.mrxs', 14.870674971593056, '210', 14.121753074501047], ['4207pylho1.mrxs', 23.774576846823003, '84', 3.5331859128851297], ['4302pglho1.mrxs', 13.883762676814838, '389', 28.018341213049528], ['4302ppvho1.mrxs', 13.534996411916305, '378', 27.927602527268213], ['4302pylho1.mrxs', 29.505218404435794, '269', 9.117031309944776], ['4307pglho1.mrxs', 23.634930534748268, '746', 31.56345219222137], ['4307ppvho1.mrxs', 36.42566131885268, '796', 21.852726105154265], ['4307pylho1.mrxs', 11.544507203971596, '653', 56.563696350360615], ['4402pglho1.mrxs', 12.124497018679763, '323', 26.64028037636249], ['4402ppvho1.mrxs', 3.3757523088122285, '54', 15.996434293782682], ['4404ppvho1.mrxs', 6.012363009771498, '40', 6.652958235387755], ['4406pylho1.mrxs', 16.977918269937, '140', 8.246005062228368], ['4408pylho1.mrxs', 3.243368674653338, '54', 16.649356091401387], ['4501ppvho1.mrxs', 24.00989610592172, '179', 7.4552592485334435], ['4502pglho1.mrxs', 21.35483389226058, '277', 12.971302019838719], ['4503ppvho1.mrxs', 36.89821467976808, '419', 11.355562962501404], ['4503pylho1.mrxs', 3.041874575207408, '42', 13.807275402581732], ['4504pglho1.mrxs', 9.537037625462915, '163', 17.091261081408202], ['4507pylho1.mrxs', 8.32697333756939, '334', 40.11061239899361]]\n"
     ]
    }
   ],
   "source": [
    "result_short = []\n",
    "\n",
    "for slide in arr_results:\n",
    "    count = float(slide[2])\n",
    "    area_mm2 = float(slide[1])\n",
    "    cell_density = count / area_mm2\n",
    "    list_temp = slide[:3]\n",
    "    list_temp.append(cell_density)\n",
    "    result_short.append(list_temp)\n",
    "    \n",
    "print(result_short)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3604pylho1.mrxs', '0', []], ['3605ppvho1.mrxs', '0', []], ['3606pglho1.mrxs', '0', []]]\n"
     ]
    }
   ],
   "source": [
    "print(arr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
